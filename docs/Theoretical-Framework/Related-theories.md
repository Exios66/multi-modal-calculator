# Framework Supporting the Premise of the Investigation

## Social Agency Theory

This theory explains why chatbots with humanoid embodiment are perceived to have greater social presence. Studies show that chatbots with humanoid embodiment (versus none) are perceived to have greater social presence, and that among different output modalities, voice elicits the highest perceived social presence while text output is perceived to have the least.

## Signal Detection Theory (SDT)

SDT provides an objective measure of cognitive fatigue that aligns with subjective experiences. It proposes that one’s ability to detect a stimulus depends not only on the stimulus intensity but also on the observer’s psychological or physiological state. This connects with detection fatigue and truth-default theory in explaining how people detect deception.
Research shows that fatigue is linked to changes in the payoff matrix between effort and reward. When participants were offered monetary rewards after experiencing fatigue, their performance improved substantially, suggesting they were motivated to overcome their fatigue when rewards increased.

## Information Manipulation Theory (IMT)

While Truth Default Theory analyzes how receivers process incoming messages with a truth bias, Information Manipulation Theory examines truth from the sender’s perspective. IMT suggests that lying may be a natural response if it’s more efficient than honest communication, challenging the notion that truth-telling is the automatic/default form of communication.

## The Media Equation: Foundational Theory of Human-Computer Relationships

The Media Equation theory provides a critical foundation for understanding why anthropomorphic chatbot designs work effectively. This theory claims that people instinctively assign human characteristics to computers and other media, treating them as real social actors. The effects of this phenomenon are profound, leading people to behave toward media in unexpected ways—most of which they are completely unaware of.

## Elaboration Likelihood Model (ELM)

The Elaboration Likelihood Model explains how persuasion operates via two different modes of information processing:
    • A central route that is more effortful and deliberate
    • A peripheral route that is less resource-demanding and less analytical
    This model connects with fuzzy trace theory’s distinction between gist and verbatim processing. In AI chatbot interactions, research shows that both central cues (recommendation reliability and accuracy) and peripheral cues (human-like empathy) significantly affect a customer’s intention to adopt an AI chatbot’s recommendation.

## Heuristic Systematic Model

Similar to ELM, this model postulates two different modes of information processing in persuasion contexts. It provides additional insights into how people process information from chatbots based on either systematic analysis or quick heuristic judgments.

Originally developed by Clifford Nass and Byron Reeves at Stanford University, Media Equation explains that people respond to media either as they would to another person (being polite, cooperative, attributing personality characteristics) or to places in the physical world, depending on the cues they receive. This automatic, unavoidable reaction happens more frequently than most people realize and provides the theoretical underpinning for why humans might default to truth when interacting with AI systems.